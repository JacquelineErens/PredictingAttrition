{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ATTEMPT AT PREDICTIVE MODELING ###\n",
    "\n",
    "#0. Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Set anything you might want to use later in the code, sucha as parameter grids, model specifications, etc\n",
    "\n",
    "### Set parameters ahead of time for scoring models ###\n",
    "scoring = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Precision (Macro)': make_scorer(precision_score, average='macro'),\n",
    "    'Recall (Macro)': make_scorer(recall_score, average='macro'),\n",
    "    'F1 Score (Macro)': make_scorer(f1_score, average='macro'),\n",
    "    'AUC': make_scorer(roc_auc_score)} # Can add others if needed\n",
    "\n",
    "# Define the parameter grid for xgboost\n",
    "param_grid_XGBoost = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample': [0.7, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.9]}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "model_XGBoost = xgb.XGBClassifier()\n",
    "\n",
    "# Define parameter grid for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5277f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Data Collection and Preprocessing:\n",
    "\n",
    "#Read in dataset\n",
    "\n",
    "#The dataset used for this is the IBM HR Dataset: https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset\n",
    "#It is free to download, publicly availab, and seems to be the dataset of choice for this sort of endeavor\n",
    "turnover_data = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "print(turnover_data.head())\n",
    "print(turnover_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc543cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Practice: Always split data at the beginning of the code to prevent any leakage\n",
    "\n",
    "def split_data_train_val_test(data, DV_Name):\n",
    "    X = data.drop(columns=[DV_Name])\n",
    "    y = data[DV_Name]\n",
    "\n",
    "    print(data.head())\n",
    "    print(data.columns)\n",
    "    print(data[DV_Name].value_counts())\n",
    "    # Split the data into training and temporary sets\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n",
    "\n",
    "    # Split the temporary set into validation and test sets\n",
    "    # The training set is 75% of the previous 80% of the data (or 60% of the overall data)\n",
    "    # The validation set is the remaining 20%, making it equivalent to the test set in size\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=9)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this dataset is incredibly clean, but if using a real dataset, you'll likely need to add a step or several for cleaning \n",
    "#and any sort of imputation of missing values, if using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize data\n",
    "def visualize_your_data(your_data):\n",
    "    for column in your_data.columns:\n",
    "        sns.histplot(data=turnover_data, x=column, kde=True, bins=your_data[column].nunique())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Feature Selection: ##\n",
    "\n",
    "#Correlation Analysis: Identify features that are highly correlated with turnover using correlation matrices or other statistical techniques.\n",
    "def check_correlation_of_features(df):\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Set color pallette\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "    # Add a title\n",
    "    plt.title('Correlation of Features', fontsize=16)\n",
    "\n",
    "    # Optionally, you may also want to add a color bar label to serve as a legend for the correlation values\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_label('Correlation Coefficient')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294fa3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544cab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Model Training and Evaluation: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Model Training and Evaluation: XGBoost\n",
    "def fit_model_and_hyperparameter_tune(ParameterGrid, ModelSpecification, Data_Splits_List, Use_Validation_Set = \"Yes\", nCV = 5):\n",
    "\n",
    "    ''' The goal of this function is to be the function that carries out both model fitting to the training set, hyperparameter/n\n",
    "    tuning, fitting to the validation set, and fitting to the test set - and in a way that's reusable with different models/n\n",
    "    Inputs:/n\n",
    "    ParameterGrid: Specify a param_grid at the beginning of the code (or multiple if evaluating different models) to pass in for hyperparameter tuning/n\n",
    "    ModelSpecification: Specify the model to use (ie neural network, XGBoost, logistic regression) and any parameters for it you don't want to tune/n\n",
    "    Data_Splits_List: Just the X_train, X_val, X_test, y_train, y_val, y_test splits of the data. A list seemed easier than 6 more parameters/n\n",
    "    Use_Validation_Set: Indicator for if you want to use train/val/test splits instead of train/test splits. Assumes use of validation set/n\n",
    "    nCV = number of folds to use in CV part of gridsearch. Defaults to that default of 5, but is formatted this way in case you want to change it '''\n",
    "\n",
    "    # Initialize GridSearch using parameters passed into function\n",
    "    grid_search = GridSearchCV(estimator=ModelSpecification, param_grid=ParameterGrid,\n",
    "                               cv=nCV, n_jobs=-1, verbose=2, scoring='accuracy') #use all available cores: n_jobs = -1\n",
    "\n",
    "    # Fit to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters, show them to the world\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f'Best Parameters: {best_params}')\n",
    "\n",
    "    #check that data was split in a way to use a validation set\n",
    "    if Use_Validation_Set == \"Yes\":\n",
    "        if len(Data_Splits_List) != 6:\n",
    "            print(\"Your data splits do not support the use of a train/validation/test split./n/nMake sure you do this at the beginning of the code\")\n",
    "        \n",
    "        # If okay, tell the model the best parameters to use so it can use them\n",
    "        best_model = ModelSpecification(**best_params)\n",
    "\n",
    "        #Then start the procedure to go fit to the training set, and if supported by the model, the validation set directly\n",
    "        Standard_Model_Fit_Procedures = ['LogisticRegression','RandomForestClassifier','SVC', 'KNeighborsClassifier', \n",
    "                                     'GaussianNB', 'DecisionTreeClassifier', 'ExtraTreesClassifier', 'GradientBoostingClassifier', \n",
    "                                     'Perceptron', 'SGDClassifier', 'RidgeClassifier', 'MLPClassifier',  # Multi-layer Perceptron\n",
    "                                     'QuadraticDiscriminantAnalysis','AdaBoostClassifier']\n",
    "\n",
    "        if type(best_model).__name__ in Standard_Model_Fit_Procedures:\n",
    "            best_model.fit(X_train, y_train)\n",
    "            \n",
    "        #other types of models come with the validation procedure built in, and additional parameter options\n",
    "        elif type(best_model).__name__ == 'XGBClassifier':\n",
    "            best_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10)\n",
    "        elif type(best_model).__name__ == 'Sequential':  # Assuming a Keras Sequential model\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "            best_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, callbacks=[early_stopping])\n",
    "        else:\n",
    "            print(f\"Training procedure for {model_name} not defined\")\n",
    "    else:\n",
    "        #Just fit to the training set without validation procedure\n",
    "        best_model = ModelSpecification(**best_params)\n",
    "\n",
    "        #Then start the procedure to go fit to the training set, and if supported by the model, the validation set directly\n",
    "        Standard_Model_Fit_Procedures = ['LogisticRegression','RandomForestClassifier','SVC', 'KNeighborsClassifier', \n",
    "                                     'GaussianNB', 'DecisionTreeClassifier', 'ExtraTreesClassifier', 'GradientBoostingClassifier', \n",
    "                                     'Perceptron', 'SGDClassifier', 'RidgeClassifier', 'MLPClassifier',  # Multi-layer Perceptron\n",
    "                                     'QuadraticDiscriminantAnalysis','AdaBoostClassifier']\n",
    "\n",
    "        if type(best_model).__name__ in Standard_Model_Fit_Procedures:\n",
    "            best_model.fit(X_train, y_train)\n",
    "            \n",
    "        #other types of models come with the validation procedure built in\n",
    "        elif type(best_model).__name__ == 'XGBClassifier':\n",
    "            best_model.fit(X_train, y_train, early_stopping_rounds=10)\n",
    "        elif type(best_model).__name__ == 'Sequential':  # Assuming a Keras Sequential model\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "            best_model.fit(X_train, y_train, epochs=100, callbacks=[early_stopping])\n",
    "        else:\n",
    "            print(f\"Training procedure for {model_name} not defined\")\n",
    "            \n",
    "    # Then evaluate on the test set\n",
    "    test_predictions = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb981e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Model Training and Evaluation: RandomForests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e3ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline():\n",
    "    X_train, X_val, X_test, y_train, y_val_y_test = split_data_train_val_test(turnover_data, DV_Name = 'Attrition')\n",
    "    #visualize_your_data(turnover_data)\n",
    "    check_correlation_of_features(turnover_data)\n",
    "    fit_model_and_hyperparameter_tune(ParameterGrid, ModelSpecification, Data_Splits_List = [X_train, X_val, X_test, y_train, y_val_y_test], Use_Validation_Set = \"Yes\", nCV = 5)\n",
    "run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
